{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceApp CycleGAN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXKCIP3-hTqk",
        "colab_type": "code",
        "outputId": "4e7138e4-371f-4fe7-aa69-e06551bcf2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aTUv_LPhUTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir images\n",
        "!tar xzf '/content/drive/My Drive/part1.tar.gz' -C images\n",
        "!tar xzf '/content/drive/My Drive/part2.tar.gz' -C images\n",
        "!tar xzf '/content/drive/My Drive/part3.tar.gz' -C images\n",
        "!mv images/part1/* images\n",
        "!mv images/part2/* images\n",
        "!mv images/part3/* images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJTq0GePjGom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r images/part1\n",
        "!rm -r images/part2\n",
        "!rm -r images/part3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm7cCnRYuD56",
        "colab_type": "code",
        "outputId": "753327d2-2077-4bdc-f63f-4316ca538856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 377.0MB 66kB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiG3MX2-mCNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from glob import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Conv2DTranspose, \\\n",
        "    ZeroPadding2D, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jn640PHEjAap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "def get_image_list(path='images', young_lower=0, young_upper=29, old_lower=30, old_upper=116):\n",
        "    images = os.listdir(path)\n",
        "    ages = {\n",
        "        'young': [],\n",
        "        'old': []\n",
        "    }\n",
        "    \n",
        "    for image in images:\n",
        "        age = int(image.split('_')[0])\n",
        "        if young_lower <= age <= young_upper:\n",
        "            ages['young'].append(image)\n",
        "        if old_upper >= age >= old_lower:\n",
        "            ages['old'].append(image)\n",
        "        \n",
        "    return ages\n",
        "\n",
        "image_dataset = get_image_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMv_huCAjhFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "def generator(gen_func, *args):\n",
        "    while True:\n",
        "        yield gen_func(*args)\n",
        "        \n",
        "def load_images(shuffle_data=True):\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    x = 128\n",
        "    images = get_image_list()['young']\n",
        "    for img in images:\n",
        "        image = cv2.imread(('images/' + img), 1)\n",
        "        image = cv2.resize(image, (x, x))\n",
        "        X1.append(image)\n",
        "        \n",
        "    images = get_image_list()['old']\n",
        "    for img in images:\n",
        "        image = cv2.imread(('images/' + img), 1)\n",
        "        image = cv2.resize(image, (x, x))\n",
        "        X2.append(image)\n",
        "        \n",
        "    X1 = np.array(X1) / 127.5 - 1.\n",
        "    X2 = np.array(X2) / 127.5 - 1.\n",
        "    \n",
        "    return X1, X2\n",
        "\n",
        "\n",
        "def load_test_batch(batch_size=2, shuffle_data=True):\n",
        "    X1 = []\n",
        "    X2 = []\n",
        "    size = 128\n",
        "    images = get_image_list()['young']\n",
        "    to_create = images[:batch_size]\n",
        "    for img in to_create:\n",
        "        image = cv2.imread('images/' + img)\n",
        "        image = cv2.resize(image, (size, size))\n",
        "        X1.append(image)\n",
        "        \n",
        "    images = get_image_list()['old']\n",
        "    to_create = images[:batch_size]\n",
        "    for img in to_create:\n",
        "        image = cv2.imread('images/' + img)\n",
        "        image = cv2.resize(image, (size, size))\n",
        "        X2.append(image)\n",
        "        \n",
        "    X1 = np.stack(X1).astype(np.float32)\n",
        "    X2 = np.stack(X2).astype(np.float32)\n",
        "    \n",
        "    if shuffle_data:\n",
        "        X1, X2 = shuffle(X1, X2)\n",
        "        \n",
        "    return (X1.astype(np.float32) / 127.5) - 1., (X2.astype(np.float32) / 127.5) - 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvlN7cVTmWdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "  \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n",
        "\n",
        "  def __init__(self, axis=1, epsilon=1e-5):\n",
        "    super(InstanceNormalization, self).__init__()\n",
        "    self.epsilon = epsilon\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.scale = self.add_weight(\n",
        "        name='scale',\n",
        "        shape=input_shape[-1:],\n",
        "        initializer=tf.random_normal_initializer(0., 0.02),\n",
        "        trainable=True)\n",
        "\n",
        "    self.offset = self.add_weight(\n",
        "        name='offset',\n",
        "        shape=input_shape[-1:],\n",
        "        initializer='zeros',\n",
        "        trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "    inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "    normalized = (x - mean) * inv\n",
        "    return self.scale * normalized + self.offset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUirq6Qsjzf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def residual_block(x):\n",
        "    \"\"\"\n",
        "    Residual block\n",
        "    \"\"\"\n",
        "    res = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    res = BatchNormalization(axis=3, momentum=0.9, epsilon=1e-5)(res)\n",
        "    res = Activation('relu')(res)\n",
        "\n",
        "    res = Conv2D(filters=128, kernel_size=3, strides=1, padding=\"same\")(res)\n",
        "    res = BatchNormalization(axis=3, momentum=0.9, epsilon=1e-5)(res)\n",
        "\n",
        "    return Add()([res, x])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3qDSemZkq9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "    \"\"\"\n",
        "    Create a generator network using the hyperparameter values defined below\n",
        "    \"\"\"\n",
        "    input_shape = (128, 128, 3)\n",
        "    residual_blocks = 6\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    # First Convolution block\n",
        "    x = Conv2D(filters=32, kernel_size=7, strides=1, padding=\"same\")(input_layer)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 2nd Convolution block\n",
        "    x = Conv2D(filters=64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 3rd Convolution block\n",
        "    x = Conv2D(filters=128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(residual_blocks):\n",
        "        x = residual_block(x)\n",
        "\n",
        "    # Upsampling blocks\n",
        "\n",
        "    # 1st Upsampling block\n",
        "    x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # 2nd Upsampling block\n",
        "    x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', use_bias=False)(x)\n",
        "    x = InstanceNormalization(axis=1)(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    # Last Convolution layer\n",
        "    x = Conv2D(filters=3, kernel_size=7, strides=1, padding=\"same\")(x)\n",
        "    output = Activation('tanh')(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model\n",
        "\n",
        "\n",
        "def build_discriminator():\n",
        "    \"\"\"\n",
        "    Create a discriminator network using the hyperparameter values defined below\n",
        "    \"\"\"\n",
        "    input_shape = (128, 128, 3)\n",
        "    hidden_layers = 3\n",
        "\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(input_layer)\n",
        "\n",
        "    # 1st Convolutional block\n",
        "    x = Conv2D(filters=64, kernel_size=4, strides=2, padding=\"valid\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "\n",
        "    # 3 Hidden Convolution blocks\n",
        "    for i in range(1, hidden_layers + 1):\n",
        "        x = Conv2D(filters=2 ** i * 64, kernel_size=4, strides=2, padding=\"valid\")(x)\n",
        "        x = InstanceNormalization(axis=1)(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "\n",
        "    # Last Convolution layer\n",
        "    output = Conv2D(filters=1, kernel_size=4, strides=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=[input_layer], outputs=[output])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGgXaO8gm6Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(originalA, generatedB, recosntructedA, originalB, generatedA, reconstructedB, path):\n",
        "    \"\"\"\n",
        "    Save images\n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(2, 3, 1)\n",
        "    ax.imshow(originalA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 2)\n",
        "    ax.imshow(generatedB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 3)\n",
        "    ax.imshow(recosntructedA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 4)\n",
        "    ax.imshow(originalB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Original\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 5)\n",
        "    ax.imshow(generatedA)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Generated\")\n",
        "\n",
        "    ax = fig.add_subplot(2, 3, 6)\n",
        "    ax.imshow(reconstructedB)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Reconstructed\")\n",
        "\n",
        "    plt.savefig(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T3Yn4Ljn8WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"/content/images\"\n",
        "batch_size = 1\n",
        "epochs = 30\n",
        "mode = 'train'\n",
        "\n",
        "if mode == 'train':\n",
        "    \"\"\"\n",
        "    Load dataset\n",
        "    \"\"\"\n",
        "    imagesA, imagesB = load_images()\n",
        "\n",
        "    # Define the common optimizer\n",
        "    common_optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    # Build and compile generator networks\n",
        "    discriminatorA = build_discriminator()\n",
        "    discriminatorB = build_discriminator()\n",
        "\n",
        "    discriminatorA.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "    discriminatorB.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
        "\n",
        "    discriminatorA.load_weights(\"/content/drive/My Drive/checkpoints/discriminatorA.h5\")\n",
        "    discriminatorB.load_weights(\"/content/drive/My Drive/checkpoints/discriminatorB.h5\")\n",
        "\n",
        "    # Build generator networks\n",
        "    generatorAToB = build_generator()\n",
        "    generatorBToA = build_generator()\n",
        "    \n",
        "    generatorAToB.save_weights(\"/content/drive/My Drive/checkpoints/generatorAToB.h5\")\n",
        "    generatorBToA.save_weights(\"/content/drive/My Drive/checkpoints/generatorBToA.h5\")\n",
        "\n",
        "    \"\"\"\n",
        "    Create an adversarial network\n",
        "    \"\"\"\n",
        "    inputA = Input(shape=(128, 128, 3))\n",
        "    inputB = Input(shape=(128, 128, 3))\n",
        "\n",
        "    # Generated images using both of the generator networks\n",
        "    generatedB = generatorAToB(inputA)\n",
        "    generatedA = generatorBToA(inputB)\n",
        "\n",
        "    # Reconstruct images back to original images\n",
        "    reconstructedA = generatorBToA(generatedB)\n",
        "    reconstructedB = generatorAToB(generatedA)\n",
        "\n",
        "    generatedAId = generatorBToA(inputA)\n",
        "    generatedBId = generatorAToB(inputB)\n",
        "\n",
        "    # Make both of the discriminator networks non-trainable\n",
        "    discriminatorA.trainable = False\n",
        "    discriminatorB.trainable = False\n",
        "\n",
        "    probsA = discriminatorA(generatedA)\n",
        "    probsB = discriminatorB(generatedB)\n",
        "\n",
        "    adversarial_model = Model(inputs=[inputA, inputB],\n",
        "                              outputs=[probsA, probsB, reconstructedA, reconstructedB,\n",
        "                                       generatedAId, generatedBId])\n",
        "    adversarial_model.compile(loss=['mse', 'mse', 'mae', 'mae', 'mae', 'mae'],\n",
        "                              loss_weights=[1, 1, 10.0, 10.0, 1.0, 1.0],\n",
        "                              optimizer=common_optimizer)\n",
        "    \n",
        "    real_labels = np.ones((batch_size, 7, 7, 1))\n",
        "    fake_labels = np.zeros((batch_size, 7, 7, 1))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5ZC0v5m-kZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH-whiC8Kn0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elif mode == 'predict':\n",
        "    # Build generator networks\n",
        "    generatorAToB = build_generator()\n",
        "    generatorBToA = build_generator()\n",
        "\n",
        "    generatorAToB.load_weights(\"generatorAToB.h5\")\n",
        "    generatorBToA.load_weights(\"generatorBToA.h5\")\n",
        "\n",
        "    # Get a batch of test data\n",
        "    batchA, batchB = load_test_batch(data_dir=data_dir, batch_size=2)\n",
        "\n",
        "    # Save images\n",
        "    generatedB = generatorAToB.predict(batchA)\n",
        "    generatedA = generatorBToA.predict(batchB)\n",
        "\n",
        "    reconsA = generatorBToA.predict(generatedB)\n",
        "    reconsB = generatorAToB.predict(generatedA)\n",
        "\n",
        "    for i in range(len(generatedA)):\n",
        "        save_images(originalA=batchA[i], generatedB=generatedB[i], recosntructedA=reconsA[i],\n",
        "                    originalB=batchB[i], generatedA=generatedA[i], reconstructedB=reconsB[i],\n",
        "                    path=\"results/test_{}\".format(i)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}